{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import math\n",
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "\n",
    "def n_gram_count(data, n):\n",
    "    n_grams = defaultdict(int)\n",
    "    for i in range(len(data)-n+1):\n",
    "        n_gram = tuple(data[i:i+n])\n",
    "        n_grams[n_gram] += 1\n",
    "    return n_grams\n",
    "\n",
    "def add_k_smoothing(data, n, k):\n",
    "    n_grams = n_gram_count(data, n)\n",
    "    vocabulary_size = len(set(data))\n",
    "    total_n_grams = sum(n_grams.values())\n",
    "    for n_gram in n_grams:\n",
    "        n_grams[n_gram] = (n_grams[n_gram] + k) / (total_n_grams + k * vocabulary_size ** n)\n",
    "    return n_grams\n",
    "\n",
    "def n_gram_smoothing(data, n, k):\n",
    "    n_grams = add_k_smoothing(data, n, k)\n",
    "    def probability(n_gram):\n",
    "        return n_grams[n_gram]\n",
    "    return probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.027777777777777776\n",
      "0.027777777777777776\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "data = [\"the\", \"quick\", \"brown\", \"fox\", \"jumps\", \"over\", \"the\", \"lazy\", \"dog\"]\n",
    "n = 2\n",
    "k = 1\n",
    "\n",
    "probability = n_gram_smoothing(data, n, k)\n",
    "\n",
    "print(probability((\"the\", \"quick\")))  # 0.125\n",
    "print(probability((\"quick\", \"brown\")))  # 0.16666666666666666\n",
    "print(probability((\"quick\",\"fox\")))  # 0.029411764705882353"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N-gram probabilities:\n",
      "('Hi', '!') -> 0.15\n",
      "('!', 'I') -> 0.15\n",
      "('I', 'am') -> 0.23\n",
      "('am', 'Hritvik') -> 0.15\n",
      "('Hritvik', 'Mathur') -> 0.15\n",
      "('Mathur', 'and') -> 0.15\n",
      "('and', 'I') -> 0.15\n",
      "('am', 'performing') -> 0.15\n",
      "('performing', 'experiment') -> 0.15\n",
      "('experiment', 'of') -> 0.15\n",
      "('of', 'natural') -> 0.15\n",
      "('natural', 'language') -> 0.15\n",
      "('language', 'processing') -> 0.15\n"
     ]
    }
   ],
   "source": [
    "# Load the text corpus\n",
    "corpus = \"Hi! I am Hritvik Mathur and I am performing experiment of natural language processing\"\n",
    "\n",
    "# Convert the corpus into tokens\n",
    "tokens = nltk.word_tokenize(corpus)\n",
    "\n",
    "# Set the value of n for n-gram smoothing\n",
    "n = 2\n",
    "\n",
    "# Create n-grams from the tokens\n",
    "n_grams = list(ngrams(tokens, n))\n",
    "\n",
    "# Count the frequency of each n-gram\n",
    "n_gram_freq = Counter(n_grams)\n",
    "\n",
    "# Count the frequency of each individual token\n",
    "token_freq = Counter(tokens)\n",
    "\n",
    "# Calculate the probability of each n-gram using n-gram smoothing\n",
    "n_gram_prob = {}\n",
    "for n_gram in n_gram_freq.keys():\n",
    "    context = n_gram[:-1]\n",
    "    count = n_gram_freq[n_gram]\n",
    "    total_count = token_freq[context]\n",
    "    prob = (count + 1) / (total_count + len(token_freq))\n",
    "    n_gram_prob[n_gram] = prob\n",
    "\n",
    "# Print the n-gram probabilities\n",
    "print(\"N-gram probabilities:\")\n",
    "for n_gram, prob in n_gram_prob.items():\n",
    "    print(\"{} -> {:.2f}\".format(n_gram, prob))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
